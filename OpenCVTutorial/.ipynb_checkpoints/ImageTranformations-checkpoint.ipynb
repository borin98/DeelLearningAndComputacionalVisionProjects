{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We gonna Realize a translation in a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "imageIn = cv2.imread(\"./ImageRGB.jpg\")\n",
    "\n",
    "# Store the height and width of the image\n",
    "\n",
    "height, width = imageIn.shape[:2]\n",
    "\n",
    "quarterHeight, quarterWidth = height/4, width/2\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "T = [1 0 Tx\n",
    "     0 1 Ty]\n",
    "     \n",
    "where T is the translation matrix\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "T = np.float32([[1, 0, quarterWidth], [0, 1, quarterWidth]])\n",
    "\n",
    "# Realizing the warpAffine to translate the image using the matrix T\n",
    "imgTrans = cv2.warpAffine(imageIn, T, (width, height))\n",
    "cv2.imshow(\"Translation\", imgTrans)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "creating a rotation image in 90 degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This function divide by two to rotate the image around its centre\n",
    "rotationMatrix = cv2.getRotationMatrix2D((width/2, height/2), 90, 1)\n",
    "\n",
    "rotatedImg =  cv2.warpAffine(imageIn, rotationMatrix, (width, height))\n",
    "\n",
    "cv2.imshow(\"Rotated Image\", rotatedImg)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Other way to rotate images\n",
    "# This method remove the black space around the image\n",
    "rotatedImg2 = cv2.transpose(imageIn)\n",
    "\n",
    "cv2.imshow(\"Rotated Image - Method 2\", rotatedImg2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scaling, re-sizing and interpolations operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a image that have size of 3/4 the original image  \n",
    "imageScaled = cv2.resize(imageIn, None, fx = 0.75, fy = 0.75)\n",
    "cv2.imshow(\"Scaling - Linear Interpolation\", imageScaled)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Double the size of the original image\n",
    "imageScaled = cv2.resize(imageIn, None, fx = 2, fy = 2, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow(\"Scaling - Cubic Interpolation\", imageScaled)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Skew the re-sizing by setting exact dimensions\n",
    "imageScaled = cv2.resize(imageIn, (900, 400), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow(\"Scaling - Skewed Size\", imageScaled)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creating pyramid images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "smallerImg = cv2.pyrDown(imageIn)\n",
    "larguerImg = cv2.pyrUp(imageIn)\n",
    "\n",
    "cv2.imshow(\"Original Image\", imageIn)\n",
    "cv2.imshow(\"Small Image\", smallerImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Larger Image\", larguerImg)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Cropping Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's get the starting pixel coordinates (top left of the cropping rectangle)\n",
    "startRow, startCol = int(height * .25), int(width * .25)\n",
    "\n",
    "# Let's get the ending pixel coordinates (bottom right)\n",
    "endRow, endCol = int(height * .75), int(width * .75)\n",
    "\n",
    "# Creating the cropping image\n",
    "croppedImg = imageIn[startRow : endRow, startCol : endCol]\n",
    "\n",
    "cv2.imshow(\"Original Image\", imageIn)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Cropped Image\", croppedImg)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a matrix of ones, then multiply it by a scalar of 100\n",
    "# This gives a matrix with the same dimensions and of the image with all the values being 100\n",
    "m = np.ones(imageIn.shape, dtype = \"uint8\") * 75\n",
    "\n",
    "# Now, we will use this to add this matrix m to the original image\n",
    "# This will increase the brightness\n",
    "addMatrix = cv2.add(imageIn, m)\n",
    "cv2.imshow(\"Add Image\", addMatrix)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Likewise, we can also subtract a matrix\n",
    "# This will decrease the brightness\n",
    "subMatrix = cv2.subtract(imageIn, m)\n",
    "cv2.imshow(\"Subtracted Image\", subMatrix)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Bitwise and Masking Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a square\n",
    "square = np.zeros((300, 300), np.uint8)\n",
    "cv2.rectangle(square, (50, 50), (250, 250), 255, -2)\n",
    "cv2.imshow(\"Square\", square)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Creating a ellipse\n",
    "ellipse = np.zeros((300, 300), np.uint8)\n",
    "cv2.ellipse(ellipse, (150, 150), (150, 150), 30, 0, 180, 255, -1)\n",
    "cv2.imshow(\"Ellipse\", ellipse)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Examples of some bitwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Shows only where they intersect\n",
    "andOp = cv2.bitwise_and(square, ellipse)\n",
    "cv2.imshow(\"And Op\", andOp)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Shows where either square or ellipse is\n",
    "orOp = cv2.bitwise_or(square, ellipse)\n",
    "cv2.imshow(\"Or Op\", orOp)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Shows where either exist by itself\n",
    "xorOp = cv2.bitwise_xor(square, ellipse)\n",
    "cv2.imshow(\"Xor Op\", xorOp)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Shows everything that is not part of the square\n",
    "notSquareOp = cv2.bitwise_not(square)\n",
    "cv2.imshow(\"Not In Square\", notSquareOp)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convolution and Blurring operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a 3 x 3 kernel operation\n",
    "kernel = np.ones((3, 3), np.float)/9\n",
    "\n",
    "# we will utilize the cv2.filter2D to convolve the kernel with an image\n",
    "blur = cv2.filter2D(imageIn, -1, kernel)\n",
    "cv2.imshow(\"3 X 3 Kernel Blurring\", blur)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Creating a 7 x 7 kernel\n",
    "kernel2 = np.ones((7, 7), np.float)/49\n",
    "\n",
    "blur2 = cv2.filter2D(imageIn, -1, kernel2)\n",
    "cv2.imshow(\"7 x 7 Kernel Blurring\", blur2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Other method to use blur in openCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " This operation is done by convolving the image with a normalized box filter.\n",
    " This takes the pixels under the box and replaces the central element\n",
    " The box size need to be always odd and positive\n",
    "\"\"\"\n",
    "blur = cv2.blur(imageIn, (3, 3))\n",
    "cv2.imshow(\"Averaging\", blur)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Instead of use the box filter, we will use the gaussina kernel \n",
    "gaussianKernel = cv2.GaussianBlur(imageIn, (7, 7), 0)\n",
    "cv2.imshow(\"Gaussian Blurring\", gaussianKernel)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# This filter takes the median of all the pixels under the kernel area and center.\n",
    "# All the elements is replaced with this median value\n",
    "median = cv2.medianBlur(imageIn, 5)\n",
    "cv2.imshow(\"Median Blurring\", median)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# This filter is very effective to remove noises in images\n",
    "# Also, this keeping the edpges sharp\n",
    "bilateral = cv2.bilateralFilter(imageIn, 9, 75, 75)\n",
    "cv2.imshow(\"Bilateral Blurring\", bilateral)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Image De-noising and Non-Local Means Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The parameters after None are - The filter strength \"h\" (5-10 is a good range)\n",
    "# Next is the hForColorComponents, set as the same value as the h\n",
    "dst = cv2.fastNlMeansDenoisingColored(imageIn, None, 6, 6, 7, 21)\n",
    "cv2.imshow(\"Fast Means Denoising\", dst)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creating a Sharpening filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create our sharpening kernel, we do not need to normalize the matrix\n",
    "# since the sum of all the values in the matrix is equal to 1\n",
    "\n",
    "kernelShp = np.array([-1, -1, -1,\n",
    "                      -1, 9, -1\n",
    "                      -1, -1, -1])\n",
    "\n",
    "# Applying this kernel on the image\n",
    "sharp = cv2.filter2D(imageIn, -1, kernelShp)\n",
    "cv2.imshow(\"Sharpening Image\", sharp)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Thresholding, an Image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Values below 127 goes to 0 (black). Everything above goes to 255 (white)\n",
    "ret1, thresh1 = cv2.threshold(imageIn, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\" 1 - Threshold Binary\", thresh1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Values below 127 goes to 255 and values above 127 goes to 0 (reverse operation from bellow)\n",
    "ret2, thresh2 = cv2.threshold(imageIn, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\" 2 - Threshold Binary Inverse\", thresh2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Values above 127 are truncated at 127.\n",
    "ret3, thresh3 = cv2.threshold(imageIn, 127, 255, cv2.THRESH_TRUNC)\n",
    "cv2.imshow(\" 3 - Threshold truncated\", thresh3)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Values below 127 goes to 0 (black).\n",
    "ret4, thresh4 = cv2.threshold(imageIn, 127, 255, cv2.THRESH_TOZERO)\n",
    "cv2.imshow(\" 4 - Threshold topzero\", thresh4)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Reverse operation from above. The values below 127 is unchanged, above 127 goes to 9\n",
    "ret5, thresh5 = cv2.threshold(imageIn, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow(\" 5 - Threshold topzero inv\", thresh5)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A better method to do a thersholding in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imageGray = cv2.cvtColor(imageIn, cv2.COLOR_BGR2GRAY)\n",
    "# It is a good practice to blur images to remove the noises\n",
    "image = cv2.GaussianBlur(imageGray, (3, 3), 0)\n",
    "\n",
    "# Using an adaptative Threshold\n",
    "thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                               cv2.THRESH_BINARY, 3, 5)\n",
    "cv2.imshow(\"Adaptive Mean Thresholding\", thresh)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Otsu's thresholding after the Gaussian filtering\n",
    "blur = cv2.GaussianBlur(imageGray, (5, 5), 0)\n",
    "_, th = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Gaussian Otsu's thresholding\", th)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Erosion, dilatation, opening and closing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# defining the kernel size\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Erosion Operation\n",
    "erosion = cv2.erode(imageGray, kernel, iterations = 1)\n",
    "cv2.imshow(\"Erosion\", erosion)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Dilatation Operation\n",
    "dilatation = cv2.dilate(imageGray, kernel, iterations = 1)\n",
    "cv2.imshow(\"Dilatation\", dilatation)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Opening Operation\n",
    "op = cv2.morphologyEx(imageGray, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow(\"Opening\", op)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Closing operation\n",
    "close = cv2.morphologyEx(imageGray, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow(\"Close\", close)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Edge detection using image gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "height, width = imageGray.shape\n",
    "\n",
    "# Extracting the Sobel Edges\n",
    "sobelX = cv2.Sobel(imageGray, cv2.CV_64F, 0, 1, ksize = 5)\n",
    "sobelY = cv2.Sobel(imageGray, cv2.CV_64F, 1, 0, ksize = 5)\n",
    "\n",
    "cv2.imshow(\"Sobel X\", sobelX)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Sobel Y\", sobelY)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobelOr = cv2.bitwise_or(sobelX, sobelY)\n",
    "cv2.imshow(\"Sobel Or\", sobelOr)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(imageGray, cv2.CV_64F)\n",
    "cv2.imshow(\"Laplacian\", laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# The canny edge detection uses the values of gradient as thresholds\n",
    "# Picking the first threshold gradient\n",
    "# Canny is the best to find edges on images\n",
    "canny = cv2.Canny(imageGray, 20, 170)\n",
    "cv2.imshow(\"Canny\", canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Perspective transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Coordinates of the 4 corners of the original image\n",
    "pointsA = np.float32([[320, 15],\n",
    "                      [700, 215],\n",
    "                      [85, 610],\n",
    "                      [530, 780]])\n",
    "\n",
    "# Coordinates of the 4 coners of the desired output\n",
    "# For this, we will use a ratio of an A4 Paper (1.41)\n",
    "pointsB = np.float32([[0, 0],\n",
    "                      [420, 0],\n",
    "                      [0, 594],\n",
    "                      [420, 594]])\n",
    "\n",
    "# We will use this to sets to compute\n",
    "# the perspective transformation matrix M\n",
    "M = cv2.getPerspectiveTransform(pointsA, pointsB)\n",
    "warped = cv2.warpPerspective(image, M, (height, width))\n",
    "cv2.imshow(\"Warped Image\", warped)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) /io/opencv/modules/imgproc/src/imgwarp.cpp:3167: error: (-215:Assertion failed) (M0.type() == CV_32F || M0.type() == CV_64F) && M0.rows == 3 && M0.cols == 3 in function 'warpPerspective'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bb2504e8a1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# the perspective transformation matrix M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAffineTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointsA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpointsB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0maffine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarpPerspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Affine Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/imgwarp.cpp:3167: error: (-215:Assertion failed) (M0.type() == CV_32F || M0.type() == CV_64F) && M0.rows == 3 && M0.cols == 3 in function 'warpPerspective'\n"
     ]
    }
   ],
   "source": [
    "# Using the affine transform, we needed only 3 coordinates to obtain\n",
    "# the correct transform\n",
    "\n",
    "# Coordinates of the 3 corners of the original image\n",
    "pointsA = np.float32([[320, 15],\n",
    "                      [700, 215],\n",
    "                      [85, 610]])\n",
    "\n",
    "# Coordinates of the 4 coners of the desired output\n",
    "# For this, we will use a ratio of an A4 Paper (1.41)\n",
    "pointsB = np.float32([[0, 0],\n",
    "                      [420, 0],\n",
    "                      [0, 594]])\n",
    "\n",
    "# We will use this to sets to compute\n",
    "# the perspective transformation matrix M\n",
    "M = cv2.getAffineTransform(pointsA, pointsB)\n",
    "affine = cv2.warpPerspective(image, M, (height, width))\n",
    "cv2.imshow(\"Affine Image\", affine)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
